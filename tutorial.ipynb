{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Json Example\n",
    "{\n",
    "\t\"S0069-06-11-00.wav\": \"신기루야!\",\n",
    "\t\"S0069-06-11-01.wav\": \"또 나타났네.\",\n",
    "\t\"S0069-06-11-02.wav\": \"신기루는 수렁이다.\",\n",
    "\t\"S0069-06-11-03.wav\": \"일, 일을 해야지.\",\n",
    "\t\"S0069-06-11-04.wav\": \"역시\",\n",
    "\t\"S0069-06-11-05.wav\": \"아무것도 없네.\",\n",
    "\t\"S0069-06-11-06.wav\": \"김팀장님 말이 맞았어.\",\n",
    "\t\"S0069-06-11-07.wav\": \"네, 저 주진우예요.\",\n",
    "\t\"S0069-06-11-08.wav\": \"출근이 빠르네요.\",\n",
    "\t\"S0069-06-11-09.wav\": \"어제는 비바람이 심했잖아요.\",\n",
    "\t\"S0069-06-11-10.wav\": \"모자가 다 날아갈 거 같더라구요.\",\n",
    "\t\"S0069-06-11-11.wav\": \"만약에 밖에 나가 돌아다녔더라면요.\",\n",
    "\t\"S0069-06-11-12.wav\": \"그랬더라면, 저건 환상이야.\",\n",
    "\t\"S0069-06-11-13.wav\": \"신기루!\",\n",
    "\t\"S0069-06-11-14.wav\": \"곧 사라질 거야.\",\n",
    "\t\"S0069-06-11-15.wav\": \"주진우, 너 정말 사람이 보고 싶구나.\",\n",
    "\t\"S0069-06-11-16.wav\": \"다른 사람이 보고 싶어.\",\n",
    "\t\"S0069-06-11-17.wav\": \"없어졌겠지?\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ModelName'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "def json2text(json_path):\n",
    "    dir_name = os.path.dirname(json_path)\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    lines = []\n",
    "    for filename, text in data.items():\n",
    "        lines.append(f'{filename}|{text}\\n')\n",
    "    with open(os.path.join(dir_name, f'{os.path.basename(json_path)[:-5]}.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2text(f'./data/{MODEL_NAME}/MP3_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./src/preprocess.py -m ModelName -f ../data/ModelName/MP3_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./src/train.py -m ModelName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json, logging\n",
    "from scipy.io import wavfile\n",
    "import torch\n",
    "sys.path.append('./src')\n",
    "from models import SynthesizerTrn\n",
    "from text import symbols, text_to_sequence\n",
    "from commons import intersperse\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AudioProcessor:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.load_tts_model()\n",
    "\n",
    "    def load_tts_model(self):\n",
    "        try:\n",
    "            with open('./assets/models/VITS/config.json', 'r') as f:\n",
    "                self.tts_config = json.load(f)\n",
    "            self.net_g = SynthesizerTrn(\n",
    "                len(symbols),\n",
    "                self.tts_config['data']['filter_length']//2+1,\n",
    "                self.tts_config['train']['segment_size']//self.tts_config['data']['hop_length'],\n",
    "                **self.tts_config['model']\n",
    "            ).to(self.device)\n",
    "            checkpoint = torch.load('./assets/models/VITS/result.pth', map_location=self.device)\n",
    "            self.net_g.load_state_dict(checkpoint['model'])\n",
    "            self.net_g.eval()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load TTS model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def generate_speech(self, text, path):\n",
    "        try:\n",
    "            text = text.replace('\\n', ' ')\n",
    "            text_norm = text_to_sequence(f'[KO]{text}[KO]')\n",
    "            if self.tts_config['data']['add_blank']:\n",
    "                text_norm = intersperse(text_norm, 0)\n",
    "            stn_tst = torch.LongTensor(text_norm).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                x_tst = stn_tst.to(self.device)\n",
    "                x_tst_lengths = torch.LongTensor([stn_tst.size(1)]).to(self.device)\n",
    "                audio = self.net_g.infer(x_tst, x_tst_lengths, noise_scale=0.667, noise_scale_w=0.8, length_scale=1)[0][0,0].data.cpu().float().numpy()\n",
    "            wavfile.write(path, self.tts_config['data']['sampling_rate'], (audio * 32767).astype('int16'))\n",
    "            return path\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to generate speech: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "audio_processor = AudioProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '안녕하세요.'\n",
    "\n",
    "tts_path = audio_processor.generate_speech(text, './test.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
